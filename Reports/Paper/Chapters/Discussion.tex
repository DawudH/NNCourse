\section{Discussion}

Defining a quantative performance measure of the networks is outside of the scope of this paper. Therefore a comparison of the results of the five architectures is mainly done by sight.

%comparison of datasets fruit and landscape, on compact net . 
\subsection{Comparing dataset}
The compact network was


%discussion on difference between YcbYcr and Cielab Effect of blur
\subsection{Comparing colorspace and effect of blur}

%overfitting of vgg16 so dataset too small
% using compact architectures better results
\subsection{Comparing network complexity}

%comparison between dilation, concat and dilation+concat
\subsection{Comparing feature localization}

%final comparison between all architectures, show massive image.
\subsection{Final comparison}

%conclusion on best network







%Gaussian blur
%It is clear that the case with $\sigma=0$, i.e. no blur, the network was unable to find any colors. Using a blur radius of $\sigma=3$ or $\sigma=5$ leads to much better results. Between these two, the $\sigma=3$ case was chosen to be the best, since it seems more inclined to pick more saturated colors. A too high blur radius will also make the training less effective since the link between texture and color becomes weaker at the edges of objects.