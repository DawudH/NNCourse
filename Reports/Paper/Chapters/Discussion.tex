\section{Discussion}

Defining a quantitative performance measure of the networks is outside of the scope of this paper. Therefore a comparison of the results of the five architectures is mainly done by sight.

%comparison of datasets fruit and landscape, on compact net . 
\subsection{Comparing datasets}
The compact network is the only network that was trained on both the landscape dataset and the fruit dataset. In figure \ref{fig:blur} the final results after 25 epochs on the landscape dataset can be seen. The algorithm seems to color landscapes to good standards. However it is concluded that landscape datasets offer less strain on the CNN, because landscapes contain only a small set of features coupled to colors. For example, trees, sea and grass cover a large amount of the landscape dataset, as opposed to the many classes of fruit in the fruit-dataset. In addition, images of landscapes offer a very low amount of spatial transformation. Strawberries and bananas come in many orientations and shapes, whereas landscapes always have a horizon where the top part is blue and the bottom part is green or brown. Therefore the landscape dataset is labeled to be a low-level test-case of the CNNs, and the fruit-dataset is used as a better performance measure for the CNNs.

%discussion on difference between YcbYcr and Cielab Effect of blur
\subsection{Comparing colorspace and effect of blur}
The only network using regression was the Compact network. Gaussian blur is used to allow the network to more easily converge towards a solution. Different kernel sizes for Gaussian blur are used, $\sigma = 0$, $\sigma = 3$ and $\sigma = 5$ which can be seen in figure \ref{fig:blur}. Using $\sigma = 0 $ results in a sepia/grayscale image.

Clearly the network is having difficulties with convergence towards an optimal solution. The target for training of the network, when not blurring, is rich of fine detail. However, these details will impose very specific solutions upon the network. To optimally fit the target data, it will converge towards an average solution, because it can not find a specific solution for each image. This results in a sepia image.

$\sigma = 3$ and $\sigma = 5$ show promising results. The difference between both pictures is marginal, however a higher $\sigma$ will result in an average color overlay, on the landscape set the whole image has a blue tint. This is why $\sigma = 3$ is chosen as optimal setting.


As for colorspace selection, a comparison is made on the Compact network that shows difference between the YCbCr and CIELab colorspaces. CIELab shows a marginal improvement in saturation compared to YCbCr. This result is indecisive for making a decision on the best colorspace. However, CIELab has the added benefit that a certain color is independent of the Luminosity. This means that, when the CIELab space is divided into bins for the classification, each bin can represent a specific color, only changing in luminosity depending on the value of the added L layer. This is why CIELab is chosen as colorspace for the classification architectures.


%overfitting of vgg16 so dataset too small
% using compact architectures better results
\subsection{Comparing network complexity}

Another aspect that can be noted is that Networks are prone to overfitting on the small dataset that is used. The fruit dataset consisted of 6000 unique images for training and 1000 images for validation, both doubled in size by mirroring them. The most complex network is the VGG16 + classification network. This architecture has 512 feature maps in the bottleneck of the network. As can be seen in \ref{fig:overfit}, the VGG16 + classification network is evidently overfitting after 10 epoch. The network complexity and dataset both compliment each other. A too complex network with a simple dataset or the other way around will both produce bad results. For the dataset the more simple architecture produced far better results.

%comparison between dilation, concat and dilation+concat
\subsection{Comparing feature localization}
As can be seen in figure \ref{fig:results}, most of the architectures offer a satisfactory performance on the fruit dataset. However interesting differences can be seen in this comparison. For example the effect of class-rebalancing is very evident between the regression and classification networks. Class-rebalancing was implemented on all the classification networks with a $\lambda$ of 0.3, except for the VGG16 classifier where $\lambda = 0.5$. The images in the classification networks offer more vibrant colors, where the colors in the regression network are more dull. The fruit dataset is biased towards green red and especially gray colors, as can be seen in figure \ref{fig:histogram}. Class-rebancing therefore offers a good solution to add in more exotic colors in the images which are less common in the dataset.

Interesting to notice, is the difference between the dilated and concatenated networks. It can be seen that both networks sometimes still have difficulty with the correct localization of the color. Both the dilated and the concatenated networks show a substantial amount of color artifacts in the output image. For example, the middle image, in figure \ref{fig:results}, consisting of the fruit bowl, both networks color a part of the kiwi red. This originates from the red used in the neighboring strawberry, the network is not accurate enough in localization of the strawberry. However a difference can be noted between the two configurations: the dilated version shows less artifacts then the concatenated networks. An explanation could be that the network gets steered to the correct colors already by mapping the grayscale value to a reduced set of colors. For example, the image with strawberries in the second picture in appendix \ref{ap:more_results}, shows a strawberry colored green. However the network has no idea whether this strawberry needs to be colored green or red, still it picks the color green. All the five networks show this behavior, this is some evidence that the network uses some of the information in the grayscale input values to map a color to the image. The concatenated network use a lot more of this information since the input layers are concatenated with the output pipeline. Thus instead of picking a 'realistic' color, the concatenated network maps more of the input information in the outline pipeline of the network, hence often creating objects that are partially colored with the ground truth color, as can be seen in the fifth row of the figure in appendix \ref{ap:more_results}. In most images, the dilated convolution network results in a more realistic coloring then the network using concatenation. However the dilated network often has difficulty in coloring images which contain a large variety of small pieces of fruit, as can be seen in the seventh row in appendix \ref{ap:more_results}.

%final comparison between all architectures, show massive image.
\subsection{Final comparison}
It is very clear that different network architectures and loss functions give different results for the network. Because of this, choosing one network over the other is not a clear-cut choice. Given this fact, the choice is made that compact classifier dilated yields the best overall performance, with only a few artifacts.

%conclusion on best network







%Gaussian blur
%It is clear that the case with $\sigma=0$, i.e. no blur, the network was unable to find any colors. Using a blur radius of $\sigma=3$ or $\sigma=5$ leads to much better results. Between these two, the $\sigma=3$ case was chosen to be the best, since it seems more inclined to pick more saturated colors. A too high blur radius will also make the training less effective since the link between texture and color becomes weaker at the edges of objects.