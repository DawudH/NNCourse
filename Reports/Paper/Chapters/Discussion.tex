\section{Discussion}

Defining a quantitative performance measure of the networks is outside of the scope of this paper. Therefore a comparison of the results of the five architectures is mainly done by sight.

%comparison of datasets fruit and landscape, on compact net . 
\subsection{Comparing datasets}
The compact network is the only network that was trained on both the landscape dataset and the fruit dataset. In figure \ref{fig:blur} the final results after 20 epochs on the landscape dataset can be seen. The algorithm seems to color landscapes to good standards. However it is concluded that landscape datasets offer less strain on the CNN, because landscapes contain only a small set of features coupled to colors. For example, trees, sea and grass cover a large amount of the landscape dataset, as opposed to the many classes of fruit in the fruit-dataset. In addition, images of landscapes offer a very low amount of spatial transformation. Strawberries and bananas come in many orientations and shapes, whereas landscapes always have a horizon where the top part is blue and the bottom part is green or brown. Therefore the landscape dataset is labeled to be a low-level test-case of the CNNs, and the fruit-dataset is used as a better performance measure for the CNNsS.

%discussion on difference between YcbYcr and Cielab Effect of blur
\subsection{Comparing colorspace and effect of blur}
The only network using regression was the Compact network. Gaussian blur is used to allow the network to more easily converge towards a solution. Different kernel intensities for Gaussian blur are used, $\sigma = 0$, $\sigma = 3$ and $\sigma = 5$ which can be seen in figure \ref{fig:blur}. Using $\sigma = 0 $ results in a sepia image. 
%This is likely an effect of the network having difficulties with convergence towards a solution. Without blurring, the network is trained on a pixel per pixel basis. This way the correct solution is difficult to find. However, averaging the whole picture with a color that is represented on average throughout the picture will give better results than pixel per pixel colorization. This is why sepia is a approperiate solution when not blurring. This is likely an effect of the network having difficulties finding a specific solution, because of the detail rich input. The network then converges towards an average due to difficulty of finding a solution for every set of details. 

{\color{red}
This is likely an effect not being able to identify features due to the noisy nature of the un-blurred image, disallowing the network to converge towards a solution. Blurring the target image helps to steer the CNN in the right direction offering better convergence. $\sigma = 3$ and $\sigma = 5$ show promising results. The difference between both pictures is marginal, however a to high $\sigma$ will result in loss of fine details. This is why $\sigma = 3$ is chosen as optimal setting.}

As for colorspace selection, a comparison is made on the Compact network that shows the effect of different colorspaces. The comparison is made between YCbCr and CIELab. CIELab shows a marginal improvement in saturation compared to YCbCr. This result is indecisive for making a decision on the best colorspace. However, CIELab has the added benefit that a certain color is clustered together when moving through the L layer. This means that, when the Lab space is divided into bins for the classification, each bin can represent a specific color, only changing in saturation and slightly in color depending on the value of the added L layer. This is why CIELab is chosen as colorspace for the classification architectures.


%overfitting of vgg16 so dataset too small
% using compact architectures better results
\subsection{Comparing network complexity}
Another aspect that can be noted is that Networks are prone to overfitting on the small dataset that is used. The fruit dataset consisted of 12000 unique images for training and 2000 images for validation. The most complex network is the VGG16 + classification network. T, this architecture has 512 feature maps in the bottleneck of the network. As can be seen in \ref{fig:overfit}, the VGG16 + classification network is evidently overfitting after ?? epochs. 

%comparison between dilation, concat and dilation+concat
\subsection{Comparing feature localization}
As can be seen in figure \ref{fig:results}, most of the architectures offer a satisfactory performance of the fruit dataset. However interesting differences can be seen in this comparison of CNN architectues. For example the effect of class-rebalancing is very evident in the comparison between the regression and classification networks. Class-rebalancing was implemented on all the classification networks with a $\lambda$ of 0.3. The images in the classification networks offer more vibrant colors, where the colors in the regression network are more dull. The fruit dataset is biased towards green red and especially grey colors. Class-rebancing therefore offers a good solution to add in more exotic colors in the images which are less comon in the dataset.

Another interesting differenc to notice, is the difference between the dilated and concatenated networks. It can be seen that the networks sometimes still have difficulty with the correct localization of the color. Both the dilated and the concatenated networks show a substantial amount of color artifacts in the output image. For example, in the middle image consisting of the fruit bowl, both networks color a part of the kiwi red. This originates from the red used in the neigbouring strawberry, the network is not accurate enough in localization of the strawberry. However a difference can be noted between the two configurations: the dilated version shows less artifacts then the concatenated networks. An explanation could be that the network gets steered to the correct colors already by mapping the greyscale value to a reduced set of colors. For example, the image of strawberries in the second picture in figure \ref{fig:moreresults} in the appendix, shows a strawberry colored green. However the network has no idea whether this stawberry needs to be colored green or red, still it picks the color green. All the five networks show this behaviour, this is some evidence that the network uses some of the information in the grayscale input values to map a color to the image. The concatenated network use a lot more of this information since the input layers are concatenated with the output pipeline. Thus instead of picking a 'realistic' color, the concatenated network maps more of the grayscale color information in the outline pipeline of the network, hence often creating objects that are partially colored with the ground truth color, as can be seen in the fifth row of figure \ref{fig:moreresults}. In most images, the dilated convolution network results in a more realistic coloring then the network using concatenation. However the dilated network often has difficulty in coloring images which contain a large variety of small pieces of fruit, as can be seen in the seventh row in figure \ref{fig:moreresults}.
%final comparison between all architectures, show massive image.
\subsection{Final comparison}

%conclusion on best network







%Gaussian blur
%It is clear that the case with $\sigma=0$, i.e. no blur, the network was unable to find any colors. Using a blur radius of $\sigma=3$ or $\sigma=5$ leads to much better results. Between these two, the $\sigma=3$ case was chosen to be the best, since it seems more inclined to pick more saturated colors. A too high blur radius will also make the training less effective since the link between texture and color becomes weaker at the edges of objects.