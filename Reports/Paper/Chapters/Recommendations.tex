\section{Recommendations}

%Recommendations: What's next
%hyperparameters research (momentum etc)
%longer training
%bigger training set
%extend usage to all images

It can be concluded that using CNNs for automatic colorization offers promising results. However, a lot of improvement can still be made on the current approach. As mentioned before overfitting is evident on the more complex datasets. Increasing the dataset or even training on large datasets such as ImageNet \cite{deng2009imagenet} would give an insight on how the colorization algorithms generalizes over multi-class training sets. 

Another addition to the research mentioned in this paper is that of model averaging. Model averaging combines the outputs of multiple CNNs with different architectures, averaging the output probabilities, resulting in a more accurate final output. Figure \ref{fig:moreresults} and \ref{fig:results} show that it is difficult to point out one best architecture. Different architectures score high on different images. Therefore model averaging would take best of all architectures and average them, resulting in a good overall result.

It would also be interesting to see how one of the CNNs mentioned above, performs in combination with the 'colorization by input' technique mentioned in section \ref{sec:intro}.


{\color{red} probability comparison on object, picking the best joint probability for a region of the image instead of per pixel}