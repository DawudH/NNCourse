\section{Recommendations}

%Recommendations: What's next
%hyperparameters research (momentum etc)
%longer training
%bigger training set
%extend usage to all images

It can be concluded that using CNNs for automatic colorization offers promising results. However, a lot of improvement can still be made on the current approach. As mentioned before overfitting is evident on the more complex datasets. Increasing the dataset or even training on large datasets such as IMAGENET \cite{deng2009imagenet} would give an insight on how the colorization algorithms generalises over multi-class training sets.\\

Another addition to the research mentioned in this paper is that of model averaging. Model averaging combines the outputs of multiple CNNs with different architectures, averaging the output probabilities, resulting in a more accurate final output. Figure \ref{fig:moreresults} and \ref{fig:results} show that it is difficult to point out one best architecture. Different architectures score high on different images. Therefore model averaging would make the best of all architectures and average them, resulting in a good overall result.\\

It would also be interesting to see how one of the CNNs mentioned above, performs in combination with the 'colorization by user input' technique mentioned in section \ref{sec:intro}. An application could be to colorize a large image, while the output of the colorization neural network for a small version of the image could be used as the color input for colorization of the large version of the image.\\

The color generation by classification does not result in one single color, but rather in an estimate of the probability distribution over all possible colors. This probability distribution is given for one single pixel, but it could be interesting to look at the joint probability distribution given for a region of pixels, to ensure a smooth distribution of color over one same-color part of an object in the image.

