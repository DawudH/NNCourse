Automatic colorization of grayscale images with no further user input has several interesting applications, of which grayscale video may be the most useful one. In this paper a comparison is made between several techniques for automatic colorization, all of them being convolutional neural networks. The color space which is used during colorization is found to have an influence on the end result, and CIELab is chosen as the most promising one. Colorization can be seen as a mapping between a grayscale input image and an output color per pixel. While viewing this as a regression problem yields satisfactory results, it is found that implementing it as a classification problem, with the output of the network being a probability distribution over the colors in a discretized color space, yields much better results. The averaging problem, which causes networks to tend towards undersaturated or sepia tones, is shown to be solved using the classification approach. Using an annealed mean with a parameter setting for picking either the mean or mode of the probability distribution yields very convincing results. Finally, a model architecture using dilated convolutions in the upscale reconstruction pipeline of the network is found to generate the most convincing colorization.

