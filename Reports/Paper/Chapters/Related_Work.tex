\section{Literature review}
Various methods are already available for colorization of greyscale images. However many of them require the input of a user during colorization to correctly colorize the image. Separated by the types of input required for colorization, there are three approaches to make the computer convert a grayscale image to a color image. Every approach uses the texture and intensity gradients of the image to link a part of an image to either a learned or specified color. The three approaches are as follows:

\textbf{Colorize by example:} Image colorization can be performed by using a target image that is related to the grayscale image in that it contains similar objects with similar colors. The objects in the grayscale image are compared to the target image via the patterns of the similar objects to find what color the similar patterns should have. For example: to colorize a grayscale image of a zebra in a Savannah, another image of a zebra in a Savannah is required. The more similar the image, the better the result is. This method is used in \cite{Charpiat}, \cite{Gupta} and \cite{Zheng}.

\textbf{Colorize by user input:} In this approach, the user specifies the color of different parts of the image by hand. While this is quite labor intensive, it guarantees that correct colors are used for the different objects in an image. For example, in the \textit{colorize by example} method the color of grass may be specified as green in the target image, whereas in reality the grayscale image contains grass that should actually be colored brown. Due to the similarities in contrast the grass will thus be colored green, but in the colorize by user input this will not be a problem. However, if the user does not know the original colors of the grayscale image, colorization is not possible. This method is used in \cite{Horiuchi} and \cite{Levin}.

\textbf{Colorize using a trained machine:} Techniques like convolutional neural networks allow training of a machine to recognize specific patterns in an image and coupling the recognized pattern to a color. This requires the use of training images of which both grayscale and color versions are available. After the training of the machine is completed, no human is needed to colorize an image, which leads to a vast decrease in time consumption during colorization. One of the biggest downsides of this method is that images are colorized based on experience with different objects of the same class as in the grayscale image. However, not all objects can be colorized purely based on their class of object, i.e. an object of class ``car" can have multiple colors, and during training multiple of these colors are shown to the machine, leading to an ambiguous mapping between object and color. It was found that if during training enough similar objects with different colors are given to the neural network, a generic sepia tone results. This method is used in \cite{Cheng}, \cite{Ho}, \cite{Krizhevsky} and \cite{Dahl}.

The present image task requires a deep neural network to be able to couple color to features in grayscale images, most likely in the form of a convolutional neural network, as used in the literature. More literature about convolutional neural networks can be found in \cite{GoodfellowBOOK}. The biggest problem with the machine learning approach to automatic colorization until now, is the case where an object does not have a characteristic color, such as a car or clothing. To solve this problem it is proposed to use generative adversarial networks, to influence the discriminator to be able to generate the right colors where there could be multiple solutions. Generative adversarial networks is described by \cite{Goodfellow} and \cite{Radford}. Another method to tackle this problem are variational Auto-encoders, altering a direct copy of the output, (variational) auto encoders are described by \cite{Gregor}, \cite{Kingma} and \cite{GoodfellowBOOK}.

The work in this paper is very much an extension to the work of \cite{Dahl}. \cite{Dahl} first converts an RGB image to the YUV colorspace. One of the advantages of the YUV colorspace is that the greyscale values can be used as the Y value. The result of this is that the output of the network, the U and V channels can be concatenated with the input of the network, resulting in a colorized image.